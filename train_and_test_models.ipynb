{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import category_encoders as ce\n",
    "from category_encoders import wrapper\n",
    "from scipy import stats\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as config:\n",
    "    cfg = yaml.safe_load(config)\n",
    "\n",
    "df = pd.read_csv(cfg[\"dataset\"])[:10**5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition all necessary functions.\n",
    "#### All implementation of these functions are described in dataset_analysis.ipynb also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_boolean_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    bool_df = df.select_dtypes(exclude=['int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'object'])\n",
    "    for column in bool_df.columns:\n",
    "        df[column] = df[column].map({True: 1.0, False: 0.0}).astype(float)\n",
    "        \n",
    "    return df\n",
    "def add_column_mean_coordinates_for_series(start: pd.Series, end: pd.Series) -> pd.Series:\n",
    "\n",
    "    fill_end = end.fillna(start)\n",
    "    new_series = (start + fill_end) / 2\n",
    "    return new_series\n",
    "\n",
    "def add_mean_coordinates_for_frame(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['Lat'] = add_column_mean_coordinates_for_series(df['Start_Lat'], df['End_Lat'])\n",
    "    df['Lng'] = add_column_mean_coordinates_for_series(df['Start_Lng'], df['End_Lng'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_num_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    nan_num_column = ['Wind_Speed(mph)',\n",
    "                      'Visibility(mi)',\n",
    "                      'Humidity(%)',\n",
    "                      'Temperature(F)',\n",
    "                      'Pressure(in)',\n",
    "                      'Precipitation(in)']\n",
    "    \n",
    "    for col_name in nan_num_column:\n",
    "        df[col_name] = df.groupby('Severity')[col_name].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "    return df\n",
    "def delete_emissions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col, upper_bound, down_bound in (\n",
    "        ('Distance(mi)', 150, -150),\n",
    "        ('Temperature(F)', 150, -50),\n",
    "        ('Pressure(in)', 50, 10),\n",
    "        ('Visibility(mi)', 100, -100),\n",
    "        ('Wind_Speed(mph)', 400, -400),\n",
    "        (\"Precipitation(in)\",10, -15),\n",
    "    ):\n",
    "        df = df.drop(df[df[col] > upper_bound].index)\n",
    "        df = df.drop(df[df[col] < down_bound].index)\n",
    "        \n",
    "    return df\n",
    "def add_new_time_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['Start_Time'] = pd.to_datetime(df['Start_Time']).dt.round(\"S\")\n",
    "    df['End_Time'] = pd.to_datetime(df['End_Time']).dt.round(\"S\")\n",
    "    df['Weather_Timestamp'] = pd.to_datetime(df['Weather_Timestamp']).dt.round(\"S\")\n",
    "\n",
    "    df.loc[df['Weather_Timestamp'].isna(), 'Weather_Timestamp'] = df['Start_Time'].loc[df['Weather_Timestamp'].isna()]\n",
    "\n",
    "    df['Start_Date_Year'] = df['Start_Time'].dt.year\n",
    "    df['Start_Date_Month'] = df['Start_Time'].dt.month\n",
    "    df['Start_Date_Day'] = df['Start_Time'].dt.day\n",
    "    df['Start_Date_Hour'] = df['Start_Time'].dt.hour\n",
    "\n",
    "    df['End_Date_Year'] = df['End_Time'].dt.year\n",
    "    df['End_Date_Month'] = df['End_Time'].dt.month\n",
    "    df['End_Date_Day'] = df['End_Time'].dt.day\n",
    "    df['End_Date_Hour'] = df['End_Time'].dt.hour\n",
    "\n",
    "    df['Weather_Datestamp_Year'] = df['Weather_Timestamp'].dt.year\n",
    "    df['Weather_Datestamp_Month'] = df['Weather_Timestamp'].dt.month\n",
    "    df['Weather_Datestamp_Day'] = df['Weather_Timestamp'].dt.day\n",
    "    df['Weather_Datestamp_Hour'] = df['Weather_Timestamp'].dt.hour\n",
    "    \n",
    "    return df\n",
    "\n",
    "new_twilight_names = {\n",
    "    'Sunrise_Sunset': 'Is_Day',\n",
    "    \"Civil_Twilight\": \"Is_Civil_Day\",\n",
    "    \"Nautical_Twilight\": \"Is_Twilight_Day\",\n",
    "    \"Astronomical_Twilight\": \"Is_Astronomical_Day\"\n",
    "}\n",
    "def rename_twillight_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for column in new_twilight_names.keys():\n",
    "        df[new_twilight_names[column]] = df[column].map({'Day': 1.0, 'Night': 0.0}).astype(float)\n",
    "    df.drop(columns=list(new_twilight_names.keys()), inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def rename_timezone_meanings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['Timezone'] = df['Timezone'].replace({\n",
    "        \"US/Eastern\": \"Easterm\",\n",
    "        \"US/Central\": \"Central\",\n",
    "        \"US/Pacific\": \"Pacific\",\n",
    "        \"US/Mountain\": \"Mountain\"\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "def rename_wind_direction_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['Wind_Direction'] = df['Wind_Direction'].replace(\n",
    "        {\n",
    "            'South': 'S',\n",
    "            'West': 'W',\n",
    "            'North': 'N',\n",
    "            'Variable': 'VAR',\n",
    "            'East': 'E',\n",
    "            'Calm': 'CALM'\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df['Wind_Direction'].fillna('VAR', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_excess_parametres(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.drop(columns=['ID',\n",
    "                           'Source',\n",
    "                           'Start_Lat',\n",
    "                           'Start_Lng',\n",
    "                           'End_Lat',\n",
    "                           'End_Lng',\n",
    "                           'Wind_Chill(F)',\n",
    "                           'Country',\n",
    "                           'Zipcode',\n",
    "                           'Airport_Code',\n",
    "                           'Description',\n",
    "                           'Street',\n",
    "                           'Weather_Timestamp',\n",
    "                           'Start_Time',\n",
    "                           'End_Time',\n",
    "                           ])\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def rename_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = rename_twillight_columns(df)\n",
    "    df = rename_timezone_meanings(df)\n",
    "    df = rename_wind_direction_columns(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def data_condersion(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = conversion_boolean_features(df)\n",
    "    df = add_mean_coordinates_for_frame(df)\n",
    "    df = fill_num_columns(df)\n",
    "    df = delete_emissions(df)\n",
    "    df = add_new_time_columns(df)\n",
    "    df = rename_columns(df)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "class WeatherEncoder(TransformerMixin):\n",
    "    \"\"\"\n",
    "    A transformer class for encoding weather conditions into understandable features.\n",
    "\n",
    "    This class takes a series of weather conditions as input and encodes them into understandable features\n",
    "    based on a predefined set of replacement words. It implements the `fit` and `transform` methods\n",
    "    required by the `TransformerMixin` interface.\n",
    "\n",
    "    Attributes:\n",
    "        words_ (set): A set of unique words extracted from the input data.\n",
    "        replacement_words_ (dict): A dictionary mapping words to their replacement values.\n",
    "\n",
    "    Methods:\n",
    "        fit(X, y=None): Fit the transformer to the input data.\n",
    "        transform(X): Transform the input data into understandable features.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.words_ = None\n",
    "        self.replacement_words_ = None\n",
    "        with open(cfg['type_weather']) as file:\n",
    "            self.replacement_words_ = json.load(file)\n",
    "            \n",
    "    def fit(self, X: NDArray, y: NDArray = None) -> None:\n",
    "        \"\"\"\n",
    "        Fit the transformer to the input data.\n",
    "\n",
    "        This method extracts unique words from the input data, replaces them with their corresponding\n",
    "        replacement values, and stores the unique words in the `words_` attribute.\n",
    "\n",
    "        Args:\n",
    "            X (ndarray): The input data.\n",
    "            y (ndarray, optional): The target data. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "\n",
    "        \"\"\"\n",
    "        self.words_ = set()\n",
    "        \n",
    "        Processed_Weather_Condition = X.dropna().apply(\n",
    "            lambda x: ' '.join(\n",
    "                set(\n",
    "                    sorted(\n",
    "                            [\n",
    "                            self.replacement_words_[word] for word in x.split(\" \") if word in self.replacement_words_.keys()\n",
    "                            ]\n",
    "                        )\n",
    "                    )\n",
    "                ) \n",
    "            )\n",
    "\n",
    "        for index in Processed_Weather_Condition.index:\n",
    "            if 'Mix' in Processed_Weather_Condition[index]:\n",
    "                Processed_Weather_Condition[index] = 'Mix'\n",
    "\n",
    "        X = Processed_Weather_Condition.replace({'': np.nan})\n",
    "        X.fillna(X.mode()[0], inplace=True)\n",
    "                    \n",
    "        return self\n",
    "                    \n",
    "    def transform(self, X: pd.Series) -> pd.Series:      \n",
    "        \"\"\"\n",
    "        Transform the input data into understable features.\n",
    "\n",
    "        This method takes the input data and encodes it into understable features based on the unique words\n",
    "        extracted during the fitting process.\n",
    "\n",
    "        Args:\n",
    "            X (pd.Series): The input data.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing the understable features.\n",
    "\n",
    "        \"\"\"\n",
    "        X.fillna(X.mode()[0], inplace=True)\n",
    "        new_columns = np.zeros((len(self.words_), len(X)), dtype=float)\n",
    "\n",
    "        for i, line in enumerate(X):\n",
    "            line_words = set(line.split(\" \"))\n",
    "            for k, word in enumerate(self.words_):\n",
    "                if word in line_words:\n",
    "                    new_columns[k][i] = 1.0\n",
    "\n",
    "        return_columns = dict()\n",
    "        for idx, word in enumerate(self.words_):\n",
    "            new_column = pd.Series(new_columns[idx])\n",
    "            new_column.index = X.index\n",
    "            return_columns[word] = new_column\n",
    "            \n",
    "        return pd.DataFrame(return_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_condersion(df)\n",
    "df = drop_excess_parametres(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_colums = df.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'Severity'\n",
    "feature_columns = list(df.columns)\n",
    "feature_columns.remove(target_column)\n",
    "\n",
    "X = df[feature_columns]\n",
    "Y = df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_encoder_city = ce.CountEncoder(normalize=True)\n",
    "x_train['City_Encoded'] = count_encoder_city.fit_transform(x_train['City'])\n",
    "x_test['City_Encoded'] = count_encoder_city.transform(x_test['City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_encoder_county = ce.CountEncoder(normalize=True)\n",
    "x_train['County_Encoded'] = count_encoder_county.fit_transform(x_train['County'])\n",
    "x_test['County_Encoded'] = count_encoder_county.transform(x_test['County'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_state = LabelEncoder()\n",
    "encoded = pd.Series(label_encoder_state.fit_transform(x_train['State']))\n",
    "encoded.index = x_train.index\n",
    "x_train['State_Encoded'] = encoded\n",
    "encoded = pd.Series(label_encoder_state.transform(x_test['State']))\n",
    "encoded.index = x_test.index\n",
    "x_test['State_Encoded'] = encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse_output=False, min_frequency=5*10**(-4), handle_unknown=\"ignore\")\n",
    "\n",
    "encoded_categorical_columns_train = pd.DataFrame(onehot_encoder.fit_transform(x_train[['Timezone', 'Wind_Direction']]))\n",
    "encoded_categorical_columns_test = pd.DataFrame(onehot_encoder.transform(x_test[['Timezone', 'Wind_Direction']]))\n",
    "\n",
    "encoded_categorical_columns_train.columns = onehot_encoder.get_feature_names_out()\n",
    "encoded_categorical_columns_train.index = x_train.index\n",
    "\n",
    "encoded_categorical_columns_test.columns = onehot_encoder.get_feature_names_out()\n",
    "encoded_categorical_columns_test.index = x_test.index\n",
    "\n",
    "for column_name in onehot_encoder.get_feature_names_out():\n",
    "    x_train[column_name] = encoded_categorical_columns_train[column_name]\n",
    "    x_test[column_name] = encoded_categorical_columns_test[column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_transformer = WeatherEncoder()\n",
    "\n",
    "encoded_train = weather_transformer.fit_transform(x_train['Weather_Condition'])\n",
    "encoded_test = weather_transformer.transform(x_test['Weather_Condition'])\n",
    "\n",
    "for word in weather_transformer.words_:\n",
    "    x_train[word] = encoded_train[word]\n",
    "    x_test[word] = encoded_test[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop(columns=['Timezone',\n",
    "                      'Wind_Direction',\n",
    "                      'Weather_Condition',\n",
    "                      'State',\n",
    "                      'County',\n",
    "                      'City'\n",
    "                      ], inplace=True)\n",
    "x_test.drop(columns=['Timezone',\n",
    "                      'Wind_Direction',\n",
    "                      'Weather_Condition',\n",
    "                      'State',\n",
    "                      'County',\n",
    "                      'City'\n",
    "                      ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m standard_scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m standard_scaler\u001b[38;5;241m.\u001b[39mfit_transform(x_train)\n\u001b[0;32m      3\u001b[0m x_test\u001b[38;5;241m.\u001b[39mloc[:, feature_columns] \u001b[38;5;241m=\u001b[39m standard_scaler\u001b[38;5;241m.\u001b[39mfit_transform(x_test)\n",
      "File \u001b[1;32mc:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:849\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    848\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 849\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1835\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1832\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[0;32m   1833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1834\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1835\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1836\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1837\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1875\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_frame_value(indexer, value, name)\n\u001b[0;32m   1872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1873\u001b[0m     \u001b[38;5;66;03m# TODO: avoid np.ndim call in case it isn't an ndarray, since\u001b[39;00m\n\u001b[0;32m   1874\u001b[0m     \u001b[38;5;66;03m#  that will construct an ndarray, which will be wasteful\u001b[39;00m\n\u001b[1;32m-> 1875\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_2d_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m lplane_indexer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(pi):\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;66;03m# We are setting multiple rows in a single column.\u001b[39;00m\n\u001b[0;32m   1879\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_column(ilocs[\u001b[38;5;241m0\u001b[39m], value, pi)\n",
      "File \u001b[1;32mc:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1941\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_2d_value\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1939\u001b[0m     value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m   1940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) \u001b[38;5;241m!=\u001b[39m value\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m-> 1941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have equal len keys and value when setting with an ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1943\u001b[0m     )\n\u001b[0;32m   1945\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, loc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ilocs):\n\u001b[0;32m   1946\u001b[0m     value_col \u001b[38;5;241m=\u001b[39m value[:, i]\n",
      "\u001b[1;31mValueError\u001b[0m: Must have equal len keys and value when setting with an ndarray"
     ]
    }
   ],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "x_train.loc[:, feature_columns] = standard_scaler.fit_transform(x_train)\n",
    "x_test.loc[:, feature_columns] = standard_scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Pressure(in)</th>\n",
       "      <th>Visibility(mi)</th>\n",
       "      <th>Wind_Speed(mph)</th>\n",
       "      <th>Precipitation(in)</th>\n",
       "      <th>Amenity</th>\n",
       "      <th>Bump</th>\n",
       "      <th>Crossing</th>\n",
       "      <th>...</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Dust</th>\n",
       "      <th>Whirls</th>\n",
       "      <th>Cloudy</th>\n",
       "      <th>Fog</th>\n",
       "      <th>Hail</th>\n",
       "      <th>Snow</th>\n",
       "      <th>Ice</th>\n",
       "      <th>Thunder</th>\n",
       "      <th>Mix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>724212</th>\n",
       "      <td>-0.125238</td>\n",
       "      <td>-1.072822</td>\n",
       "      <td>1.143062</td>\n",
       "      <td>0.479091</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>1.496071</td>\n",
       "      <td>-0.101755</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.506464</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>-0.125238</td>\n",
       "      <td>2.033292</td>\n",
       "      <td>-2.429342</td>\n",
       "      <td>0.173988</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>0.295964</td>\n",
       "      <td>-0.009684</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663806</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855204</th>\n",
       "      <td>-0.125238</td>\n",
       "      <td>0.192632</td>\n",
       "      <td>-2.337742</td>\n",
       "      <td>-1.109983</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>0.461496</td>\n",
       "      <td>0.032793</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663806</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801341</th>\n",
       "      <td>-0.125238</td>\n",
       "      <td>-0.440095</td>\n",
       "      <td>-1.925542</td>\n",
       "      <td>0.517228</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>0.047666</td>\n",
       "      <td>-0.101755</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663806</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628599</th>\n",
       "      <td>-0.125238</td>\n",
       "      <td>0.710317</td>\n",
       "      <td>0.227061</td>\n",
       "      <td>0.479091</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>0.461496</td>\n",
       "      <td>-0.101755</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.506464</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264895</th>\n",
       "      <td>-0.117590</td>\n",
       "      <td>-0.727698</td>\n",
       "      <td>0.776661</td>\n",
       "      <td>0.453665</td>\n",
       "      <td>-0.077112</td>\n",
       "      <td>-0.407547</td>\n",
       "      <td>-0.009684</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663806</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373331</th>\n",
       "      <td>0.884337</td>\n",
       "      <td>-0.842739</td>\n",
       "      <td>1.051461</td>\n",
       "      <td>0.301114</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>2.447880</td>\n",
       "      <td>-0.101755</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663806</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134069</th>\n",
       "      <td>-0.125238</td>\n",
       "      <td>0.997920</td>\n",
       "      <td>-0.368340</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>1.020166</td>\n",
       "      <td>-0.009684</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>2.583518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.506464</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685564</th>\n",
       "      <td>-0.125238</td>\n",
       "      <td>-1.935631</td>\n",
       "      <td>-0.688940</td>\n",
       "      <td>0.695205</td>\n",
       "      <td>-0.009456</td>\n",
       "      <td>0.461496</td>\n",
       "      <td>-0.101755</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663806</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123952</th>\n",
       "      <td>-0.117590</td>\n",
       "      <td>-0.014442</td>\n",
       "      <td>-0.459940</td>\n",
       "      <td>0.440953</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>-0.023545</td>\n",
       "      <td>-0.009684</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>2.583518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663806</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784164 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Distance(mi)  Temperature(F)  Humidity(%)  Pressure(in)  \\\n",
       "724212     -0.125238       -1.072822     1.143062      0.479091   \n",
       "3957       -0.125238        2.033292    -2.429342      0.173988   \n",
       "855204     -0.125238        0.192632    -2.337742     -1.109983   \n",
       "801341     -0.125238       -0.440095    -1.925542      0.517228   \n",
       "628599     -0.125238        0.710317     0.227061      0.479091   \n",
       "...              ...             ...          ...           ...   \n",
       "264895     -0.117590       -0.727698     0.776661      0.453665   \n",
       "373331      0.884337       -0.842739     1.051461      0.301114   \n",
       "134069     -0.125238        0.997920    -0.368340      0.491803   \n",
       "685564     -0.125238       -1.935631    -0.688940      0.695205   \n",
       "123952     -0.117590       -0.014442    -0.459940      0.440953   \n",
       "\n",
       "        Visibility(mi)  Wind_Speed(mph)  Precipitation(in)   Amenity  \\\n",
       "724212        0.369266         1.496071          -0.101755 -0.119052   \n",
       "3957          0.369266         0.295964          -0.009684 -0.119052   \n",
       "855204        0.369266         0.461496           0.032793 -0.119052   \n",
       "801341        0.369266         0.047666          -0.101755 -0.119052   \n",
       "628599        0.369266         0.461496          -0.101755 -0.119052   \n",
       "...                ...              ...                ...       ...   \n",
       "264895       -0.077112        -0.407547          -0.009684 -0.119052   \n",
       "373331        0.369266         2.447880          -0.101755 -0.119052   \n",
       "134069        0.369266         1.020166          -0.009684 -0.119052   \n",
       "685564       -0.009456         0.461496          -0.101755 -0.119052   \n",
       "123952        0.369266        -0.023545          -0.009684 -0.119052   \n",
       "\n",
       "            Bump  Crossing  ...      Rain      Dust  Whirls    Cloudy  \\\n",
       "724212 -0.017715 -0.387069  ... -0.253852 -0.006961     0.0  1.506464   \n",
       "3957   -0.017715 -0.387069  ... -0.253852 -0.006961     0.0 -0.663806   \n",
       "855204 -0.017715 -0.387069  ... -0.253852 -0.006961     0.0 -0.663806   \n",
       "801341 -0.017715 -0.387069  ... -0.253852 -0.006961     0.0 -0.663806   \n",
       "628599 -0.017715 -0.387069  ... -0.253852 -0.006961     0.0  1.506464   \n",
       "...          ...       ...  ...       ...       ...     ...       ...   \n",
       "264895 -0.017715 -0.387069  ... -0.253852 -0.006961     0.0 -0.663806   \n",
       "373331 -0.017715 -0.387069  ... -0.253852 -0.006961     0.0 -0.663806   \n",
       "134069 -0.017715  2.583518  ... -0.253852 -0.006961     0.0  1.506464   \n",
       "685564 -0.017715 -0.387069  ... -0.253852 -0.006961     0.0 -0.663806   \n",
       "123952 -0.017715  2.583518  ... -0.253852 -0.006961     0.0 -0.663806   \n",
       "\n",
       "             Fog      Hail     Snow       Ice   Thunder       Mix  \n",
       "724212 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "3957   -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "855204 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "801341 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "628599 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "...          ...       ...      ...       ...       ...       ...  \n",
       "264895 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "373331 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "134069 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "685564 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "123952 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "\n",
       "[784164 rows x 80 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(algorithm=&#x27;brute&#x27;, metric=&#x27;euclidean&#x27;, n_neighbors=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(algorithm=&#x27;brute&#x27;, metric=&#x27;euclidean&#x27;, n_neighbors=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', metric='euclidean', n_neighbors=300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=300,\n",
    "                           metric=\"euclidean\",\n",
    "                           algorithm=\"brute\",\n",
    "                           weights=\"uniform\"\n",
    "                           )\n",
    "\n",
    "knn.fit(X=x_train, y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.6283921130196158\n",
      "test=0.6235897957109462\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = knn.predict(X=x_train)\n",
    "y_test_pred = knn.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "1. With the algorithm \"brute\" and uniform weights, and using different metrics, we obtained approximately the same results for $10^5$ samples, and for $10^6$ samples, the results were about the same.\n",
    "\n",
    "2. The Ball_Tree method gave approximately the same results.\n",
    "\n",
    "3. The KD-tree method did not improve the results.\n",
    "\n",
    "4. When the number of nearest neighbors was set to 300, the results became approximately equal. This suggests that the model may have been over fitted with a small number of training samples. The final results for both datasets were approximately 0.62.\n",
    "\n",
    "5. For $10^6$ samples, it took approximately 22 minutes to complete, which suggests that it may not be suitable for very large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=10, min_samples_leaf=200, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, min_samples_leaf=200, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, min_samples_leaf=200, random_state=0)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, min_samples_leaf=200, criterion='gini', random_state=0)\n",
    "tree.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.8389342025392648\n",
      "test=0.8376768125035069\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = tree.predict(X=x_train)\n",
    "y_test_pred = tree.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: \n",
    "1. The decision tree provides a reasonably accurate prediction, with an accuracy of approximately 0.8 on a dataset with $10^6$ elements. However, for Severity level 42, the prediction is not accurate at all.\n",
    "\n",
    "2. By experimenting with the number of splits and maximum depth, it is possible to improve the accuracy. However, even with these optimizations, Severity 4 is still not accurately predicted.\n",
    "\n",
    "3. Switching from the Gini impurity to the entropy criterion does not significantly change the results.\n",
    "\n",
    "4. As the dataset size increases, the model begins to accurately predict Severity 4, although the proportion of correct predictions remains approximately 0.9.\n",
    "\n",
    "5. With a maximum depth of 10 and a minimum number of samples per leaf of 500 and using the Gini criterion, the model accurately predicts all four Severity levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, min_samples_leaf=30, n_estimators=10,\n",
       "                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, min_samples_leaf=30, n_estimators=10,\n",
       "                       random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5, min_samples_leaf=30, n_estimators=10,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=10,\n",
    "                                       max_depth=5,\n",
    "                                       min_samples_leaf=30,\n",
    "                                       criterion=\"gini\",\n",
    "                                       random_state=0,\n",
    "                                       )\n",
    "random_forest.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.9651641426974286\n",
      "test=0.9687976420367923\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = random_forest.predict(X=x_train)\n",
    "y_test_pred = random_forest.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: <br>\n",
    "The decision tree performs better, which is likely due to the presence of a large number of instances with two and three features. The random forest takes into account specific features, while also attempting to utilize various indicators. However, there is an excessive amount of data with two and three attributes, and everything falls within these categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=8,\n",
       "                                                   min_samples_leaf=200,\n",
       "                                                   random_state=0),\n",
       "                  max_features=0.9, max_samples=0.8, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=8,\n",
       "                                                   min_samples_leaf=200,\n",
       "                                                   random_state=0),\n",
       "                  max_features=0.9, max_samples=0.8, random_state=0)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=8, min_samples_leaf=200, random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=8, min_samples_leaf=200, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=8,\n",
       "                                                   min_samples_leaf=200,\n",
       "                                                   random_state=0),\n",
       "                  max_features=0.9, max_samples=0.8, random_state=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging = BaggingClassifier(n_estimators=10,\n",
    "                            max_samples=0.8,\n",
    "                            max_features=0.9,\n",
    "                            random_state=0,\n",
    "                            estimator=DecisionTreeClassifier(max_depth=8,\n",
    "                                                             min_samples_leaf=200,\n",
    "                                                             criterion='gini',\n",
    "                                                             random_state=0\n",
    "                                                             )\n",
    "                            )\n",
    "bagging.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.9766871633296067\n",
      "test=0.9763187315784124\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = bagging.predict(X=x_train)\n",
    "y_test_pred = bagging.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "1) Using Bagging with a Decision Tree Classifier with n_estimators = 3, max_samples = 0.8 and max_features = 0.9 produces very good results. At $10^5$, the accuracy is approximately 0.97, and the model correctly predicts all Severity levels.\n",
    "\n",
    "2) However, when using a larger dataset, retraining the model does not significantly improve the results. Changing parameters also does not produce a significant impact on the situation.\n",
    "\n",
    "3) Using a Decision Tree Classifier for the estimator does not lead to full retraining of the dataset, but the accuracy decreases to 0.89. It is worth noting, however, that 1 and 4 were not predicted well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;sigmoid&#x27;, max_iter=8000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;sigmoid&#x27;, max_iter=8000, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='sigmoid', max_iter=8000, random_state=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel=\"sigmoid\",\n",
    "          max_iter=8000,\n",
    "          random_state=0\n",
    "          )\n",
    "svm.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.5725175322695396\n",
      "test=0.5743978046549446\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = svm.predict(X=x_train)\n",
    "y_test_pred = svm.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "1) A Support Vector Machine (SVM) with a linear kernel is not effective. The accuracy of the model is 0.54.\n",
    "\n",
    "2) An SVM with a polynomial kernel also does not yield good results. The accuracy remains at 0.44, even when the degree of the polynomial is varied.\n",
    "\n",
    "3) An SVM using a radial basis function (RBF) also proves to be ineffective, with an accuracy of 0.47.\n",
    "\n",
    "4) Finally, an SVM with the sigmoid kernel also fails to deliver accurate predictions, with an average accuracy of 0.57."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='multinomial')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "logistic_regression.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.7907031493025745\n",
      "test=0.7905310435720913\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = logistic_regression.predict(X=x_train)\n",
    "y_test_pred = logistic_regression.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinLogisticClassifier(BaseEstimator):\n",
    "    def __init__(self, classes: list | None = None) -> None:\n",
    "        super().__init__()\n",
    "        self.classes_ = classes\n",
    "        self._Regressors = [\n",
    "            LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\"), # x_1, x_2 | x_3, x_4\n",
    "            LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\"), # x_1 | x_2\n",
    "            LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\") # x_3 | x_4\n",
    "        ]\n",
    "        \n",
    "    def fit(self, X: NDArray, y: NDArray) -> None:\n",
    "        train_classes = set(y)\n",
    "        if self.classes_ == None:\n",
    "            self.classes_ = list(train_classes)\n",
    "        elif not self.classes_ == train_classes:\n",
    "            ValueError(\"Not all classes were passed during initialization\") \n",
    "        \n",
    "        first_cls, second_cls = self.classes_[:2], self.classes_[2:]\n",
    "        \n",
    "        y_train_bin = [\n",
    "            0 if cls in first_cls else 1\n",
    "            for cls in y \n",
    "            ]\n",
    "        \n",
    "        self._Regressors[0].fit(X=X, y=y_train_bin)\n",
    "        \n",
    "        mask = y.isin(first_cls)\n",
    "        \n",
    "        first_X = X.loc[mask]\n",
    "        second_X = X.loc[~mask]\n",
    "        \n",
    "        first_y_train_bin = pd.Series([\n",
    "            0 if cls == first_cls[0] else 1\n",
    "            for cls in y.loc[mask]\n",
    "        ])\n",
    "        second_y_train_bin = pd.Series([\n",
    "            0 if cls == second_cls[0] else 1\n",
    "            for cls in y.loc[~mask]\n",
    "        ])\n",
    "        \n",
    "        self._fit(X=first_X, y=first_y_train_bin, bin_cls=0)\n",
    "        self._fit(X=second_X, y=second_y_train_bin, bin_cls=1)\n",
    "        \n",
    "    def _fit(self, X: pd.DataFrame, y: pd.Series, bin_cls: int) -> None:\n",
    "        self._Regressors[1 + bin_cls].fit(X=X, y=y)\n",
    "        \n",
    "    def predict(self, X: NDArray) -> NDArray:\n",
    "        y_bin = self._Regressors[0].predict(X=X)\n",
    "        mask = y_bin == 0\n",
    "        \n",
    "        first_X = X.loc[mask]\n",
    "        second_X = X.loc[~mask]\n",
    "                \n",
    "        y_bins = [None, None]\n",
    "        y_bins[0] = self._predict(first_X, 0)\n",
    "        y_bins[1] = self._predict(second_X, 1)\n",
    "        \n",
    "        k = [-1, -1]\n",
    "        encoded_classes = list()\n",
    "        \n",
    "        for cls in y_bin:\n",
    "            k[cls] += 1\n",
    "            encoded_classes.append((cls, y_bins[cls][k[cls]]))\n",
    "            \n",
    "        return np.array([\n",
    "            self._decode(cls) for cls in encoded_classes\n",
    "        ])\n",
    "            \n",
    "    def _predict(self, X: pd.DataFrame, bin_cls: int) -> NDArray:\n",
    "        return self._Regressors[1 + bin_cls].predict(X=X)\n",
    "    \n",
    "    def _decode(self, code: tuple):\n",
    "        code_book = {\n",
    "            (0, 0): self.classes_[0],\n",
    "            (0, 1): self.classes_[1],\n",
    "            (1, 0): self.classes_[2],\n",
    "            (1, 1): self.classes_[3]\n",
    "        }\n",
    "        return code_book[code]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_logistic_regression = BinLogisticClassifier([1, 4, 2, 3])\n",
    "bin_logistic_regression.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 73)) while a minimum of 1 is required by LogisticRegression.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[206], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbin_logistic_regression\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m bin_logistic_regression\u001b[38;5;241m.\u001b[39mpredict(X\u001b[38;5;241m=\u001b[39mx_test)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score(y_true\u001b[38;5;241m=\u001b[39my_train,\u001b[38;5;250m \u001b[39my_pred\u001b[38;5;241m=\u001b[39my_train_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score(y_true\u001b[38;5;241m=\u001b[39my_test,\u001b[38;5;250m \u001b[39my_pred\u001b[38;5;241m=\u001b[39my_test_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[204], line 55\u001b[0m, in \u001b[0;36mBinLogisticClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     52\u001b[0m second_X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m     54\u001b[0m y_bins \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m---> 55\u001b[0m y_bins[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m y_bins[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(second_X, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     58\u001b[0m k \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[204], line 70\u001b[0m, in \u001b[0;36mBinLogisticClassifier._predict\u001b[1;34m(self, X, bin_cls)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: pd\u001b[38;5;241m.\u001b[39mDataFrame, bin_cls: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDArray:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Regressors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbin_cls\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:967\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 967\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    968\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    969\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    970\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    971\u001b[0m         )\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    974\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 73)) while a minimum of 1 is required by LogisticRegression."
     ]
    }
   ],
   "source": [
    "y_train_pred = bin_logistic_regression.predict(X=x_train)\n",
    "y_test_pred = bin_logistic_regression.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionReductingClassifier(BaseEstimator):\n",
    "    def __init__(self, classes: list | None = None) -> None:\n",
    "        super().__init__()\n",
    "        self.classes_ = classes\n",
    "        self._Regressors = [\n",
    "            LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\"), # x_1, x_2, x_3 | x_4\n",
    "            LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\"), # x_1,  x_2 | x_3\n",
    "            LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\") # x_1 | x_2\n",
    "        ]\n",
    "        \n",
    "    def fit(self, X: NDArray, y: NDArray) -> None:\n",
    "        train_classes = set(y)\n",
    "        if self.classes_ == None:\n",
    "            self.classes_ = list(train_classes)\n",
    "        elif not self.classes_ == train_classes:\n",
    "            ValueError(\"Not all classes were passed during initialization\") \n",
    "            \n",
    "        for i in range(len(self._Regressors)):\n",
    "            classes = self.classes_[:len(self._Regressors) + 1 - i]\n",
    "            mask = y.isin(classes)\n",
    "            self._fit(X=X[mask], y=y[mask], n_regressor=i, classes=classes)\n",
    "        \n",
    "    def _fit(self, X: pd.DataFrame, y: pd.Series, n_regressor: int, classes: list) -> None:\n",
    "        first_cls, second_cls = classes[:-1], classes[-1]\n",
    "        \n",
    "        y_train_bin = [\n",
    "            0 if cls in first_cls else 1\n",
    "            for cls in y \n",
    "            ]\n",
    "        \n",
    "        self._Regressors[n_regressor].fit(X=X, y=y_train_bin)\n",
    "        \n",
    "    def predict(self, X: pd.DataFrame) -> NDArray:\n",
    "        \n",
    "        y_predict = np.zeros(len(X), dtype=int)\n",
    "        \n",
    "        for i in range(len(self._Regressors)):\n",
    "            y_bin = self._predict(X=X, n_regressor=i)\n",
    "            mask = y_bin == 0\n",
    "            X = X.loc[mask]\n",
    "            k = 0\n",
    "            for idx, y in enumerate(y_predict):\n",
    "                if y == 0:\n",
    "                    if y_bin[k] == 1:\n",
    "                        y_predict[idx] = self.classes_[-(i + 1)]\n",
    "                    k += 1\n",
    "                    \n",
    "            if len(X) == 0: \n",
    "                return y_predict\n",
    "            \n",
    "        return y_predict\n",
    "            \n",
    "            \n",
    "    def _predict(self, X: pd.DataFrame, n_regressor: int) -> NDArray:\n",
    "        return self._Regressors[n_regressor].predict(X=X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_reducting = LogisticRegressionReductingClassifier([1, 4, 3, 2])\n",
    "logistic_regression_reducting.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "train=0.6371709523325542\n",
      "test=0.6441711556052444\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = logistic_regression_reducting.predict(X=x_train)\n",
    "y_test_pred = logistic_regression_reducting.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "1) Based on a large dataset, logistic regression produces a fairly accurate result, approximately 0.8.\n",
    "\n",
    "2) If you use a sufficiently large dataset, the main issue is that during the first iteration of the regression, there is a tendency for the model to overfit, which can lead to problems and rarely produces accurate predictions for 1 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bassian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bassian = GaussianNB()\n",
    "bassian.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.04845512755361317\n",
      "test=0.552393535928448\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = bassian.predict(X=x_train)\n",
    "y_test_pred = bassian.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "Due to the fact that the data is unbalanced, the results are not accurate. Additionally, it should be noted that the assumption of uncorrelated data may not be valid. There is a slight error in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis(solver=&#x27;lsqr&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis(solver=&#x27;lsqr&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis(solver='lsqr')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminant_analyse = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "discriminant_analyse.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.6319239760138226\n",
      "test=0.6391401565199716\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = discriminant_analyse.predict(X=x_train)\n",
    "y_test_pred = discriminant_analyse.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m gradient_boosting \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier()\n\u001b[1;32m----> 2\u001b[0m gradient_boosting\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39m\u001b[43mx_train\u001b[49m, y\u001b[38;5;241m=\u001b[39my_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "gradient_boosting = GradientBoostingClassifier()\n",
    "gradient_boosting.fit(X=x_train, y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = gradient_boosting.predict(X=x_train)\n",
    "y_test_pred = gradient_boosting.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_gradient_boosting = HistGradientBoostingClassifier()\n",
    "hist_gradient_boosting.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = hist_gradient_boosting.predict(X=x_train)\n",
    "y_test_pred = hist_gradient_boosting.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: 73, 2: 43259, 3: 35354, 4: 26}, {1: 0, 2: 43321, 3: 35391, 4: 0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_predicted_Severity = dict.fromkeys([1, 2, 3, 4], 0)\n",
    "count_real_Severity = dict.fromkeys([1, 2, 3, 4], 0)\n",
    "\n",
    "for p, r in zip(y_train_pred, y_train):\n",
    "    count_real_Severity[r] += 1\n",
    "    count_predicted_Severity[p] += 1\n",
    "    \n",
    "count_real_Severity, count_predicted_Severity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
