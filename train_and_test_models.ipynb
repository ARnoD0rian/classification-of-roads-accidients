{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data manipulation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import category_encoders as ce\n",
    "from category_encoders import wrapper\n",
    "from scipy import stats\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as config:\n",
    "    cfg = yaml.safe_load(config)\n",
    "df = pd.read_csv(cfg[\"dataset\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition all necessary functions.\n",
    "#### All implementation of these functions are described in dataset_analysis.ipynb also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_boolean_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Convert boolean features to float.\n",
    "    # True -> 1.0, False -> 0.0\n",
    "    bool_df = df.select_dtypes(exclude=['int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'object'])\n",
    "    for column in bool_df.columns:\n",
    "        df[column] = df[column].map({True: 1.0, False: 0.0}).astype(float)\n",
    "        \n",
    "    return df\n",
    "def add_column_mean_coordinates_for_series(start: pd.Series, end: pd.Series) -> pd.Series:\n",
    "    # For series parameters\n",
    "    \n",
    "    # Add new column with mean coordinates.\n",
    "    # If end value is NaN, fill it with start value.\n",
    "    fill_end = end.fillna(start)\n",
    "    # Calculate mean value.\n",
    "    new_series = (start + fill_end) / 2\n",
    "    return new_series\n",
    "\n",
    "def add_mean_coordinates_for_frame(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # For frame parameter\n",
    "    \n",
    "    # Add new columns with mean coordinates. \n",
    "    df['Lat'] = add_column_mean_coordinates_for_series(df['Start_Lat'], df['End_Lat'])\n",
    "    df['Lng'] = add_column_mean_coordinates_for_series(df['Start_Lng'], df['End_Lng'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Columns with NaN values, that should be replaced\n",
    "nan_num_column = ['Wind_Speed(mph)', #mean\n",
    "                  'Visibility(mi)', #mean\n",
    "                  'Humidity(%)', #mean\n",
    "                  'Temperature(F)', #mean\n",
    "                  'Pressure(in)', #mean\n",
    "                  'Precipitation(in)' #mean\n",
    "                  ]\n",
    "\n",
    "def fill_num_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Fill NaN values in columns with mean values.\n",
    "    for col_name in nan_num_column:\n",
    "        df[col_name] = df.groupby('Severity')[col_name].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "    return df\n",
    "def delete_emissions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Delete rows with emissions.\n",
    "    for col, upper_bound, down_bound in (\n",
    "        ('Distance(mi)', 150, -150),\n",
    "        ('Temperature(F)', 150, -50),\n",
    "        ('Pressure(in)', 50, 10),\n",
    "        ('Visibility(mi)', 100, -100),\n",
    "        ('Wind_Speed(mph)', 400, -400),\n",
    "        (\"Precipitation(in)\",10, -15),\n",
    "    ):\n",
    "        df = df.drop(df[df[col] > upper_bound].index)\n",
    "        df = df.drop(df[df[col] < down_bound].index)\n",
    "        \n",
    "    return df\n",
    "def add_new_time_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Convert time columns to accurate format.\n",
    "    df['Start_Time'] = pd.to_datetime(df['Start_Time']).dt.round(\"S\")\n",
    "    df['End_Time'] = pd.to_datetime(df['End_Time']).dt.round(\"S\")\n",
    "    df['Weather_Timestamp'] = pd.to_datetime(df['Weather_Timestamp']).dt.round(\"S\")\n",
    "\n",
    "    df.loc[df['Weather_Timestamp'].isna(), 'Weather_Timestamp'] = df['Start_Time'].loc[df['Weather_Timestamp'].isna()]\n",
    "\n",
    "    df['Start_Date_Year'] = df['Start_Time'].dt.year\n",
    "    df['Start_Date_Month'] = df['Start_Time'].dt.month\n",
    "    df['Start_Date_Day'] = df['Start_Time'].dt.day\n",
    "    df['Start_Date_Hour'] = df['Start_Time'].dt.hour\n",
    "\n",
    "    df['End_Date_Year'] = df['End_Time'].dt.year\n",
    "    df['End_Date_Month'] = df['End_Time'].dt.month\n",
    "    df['End_Date_Day'] = df['End_Time'].dt.day\n",
    "    df['End_Date_Hour'] = df['End_Time'].dt.hour\n",
    "\n",
    "    df['Weather_Datestamp_Year'] = df['Weather_Timestamp'].dt.year\n",
    "    df['Weather_Datestamp_Month'] = df['Weather_Timestamp'].dt.month\n",
    "    df['Weather_Datestamp_Day'] = df['Weather_Timestamp'].dt.day\n",
    "    df['Weather_Datestamp_Hour'] = df['Weather_Timestamp'].dt.hour\n",
    "    \n",
    "    return df\n",
    "\n",
    "# New names for columns\n",
    "new_twilight_names = {\n",
    "    'Sunrise_Sunset': 'Is_Day',\n",
    "    \"Civil_Twilight\": \"Is_Civil_Day\",\n",
    "    \"Nautical_Twilight\": \"Is_Twilight_Day\",\n",
    "    \"Astronomical_Twilight\": \"Is_Astronomical_Day\"\n",
    "}\n",
    "def rename_twillight_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Rename columns with twilights to more understandable names.\n",
    "    for column in new_twilight_names.keys():\n",
    "        df[new_twilight_names[column]] = df[column].map({'Day': 1.0, 'Night': 0.0}).astype(float)\n",
    "    df.drop(columns=list(new_twilight_names.keys()), inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def rename_timezone_meanings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Rename Timezone meanings.\n",
    "    df['Timezone'] = df['Timezone'].replace({\n",
    "        \"US/Eastern\": \"Easterm\",\n",
    "        \"US/Central\": \"Central\",\n",
    "        \"US/Pacific\": \"Pacific\",\n",
    "        \"US/Mountain\": \"Mountain\"\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "def rename_wind_direction_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Rename Wind Direction meanings.\n",
    "    df['Wind_Direction'] = df['Wind_Direction'].replace({'South': 'S',\n",
    "                                                                     'West': 'W',\n",
    "                                                                     'North': 'N',\n",
    "                                                                     'Variable': 'VAR',\n",
    "                                                                     'East': 'E',\n",
    "                                                                     'Calm': 'CALM'\n",
    "                                                                     })\n",
    "\n",
    "    df['Wind_Direction'].fillna('VAR', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_excess_parametres(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Drop columns with unnecessary information.\n",
    "    df = df.drop(columns=['ID',\n",
    "                           'Source',\n",
    "                           'Start_Lat',\n",
    "                           'Start_Lng',\n",
    "                           'End_Lat',\n",
    "                           'End_Lng',\n",
    "                           'Wind_Chill(F)',\n",
    "                           'Country',\n",
    "                           'Zipcode',\n",
    "                           'Airport_Code',\n",
    "                           'Description',\n",
    "                           'Street',\n",
    "                           'Weather_Timestamp',\n",
    "                           'Start_Time',\n",
    "                           'End_Time',\n",
    "                           ])\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def rename_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Common function for renaming columns.\n",
    "    df = rename_twillight_columns(df)\n",
    "    df = rename_timezone_meanings(df)\n",
    "    df = rename_wind_direction_columns(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def data_condersion(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Common function for data conversion.\n",
    "    df = conversion_boolean_features(df)\n",
    "    df = add_mean_coordinates_for_frame(df)\n",
    "    df = fill_num_columns(df)\n",
    "    df = delete_emissions(df)\n",
    "    df = add_new_time_columns(df)\n",
    "    df = rename_columns(df)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "class WeatherEncoder(TransformerMixin):\n",
    "    \"\"\"\n",
    "    A transformer class for encoding weather conditions into understandable features.\n",
    "\n",
    "    This class takes a series of weather conditions as input and encodes them into understandable features\n",
    "    based on a predefined set of replacement words. It implements the `fit` and `transform` methods\n",
    "    required by the `TransformerMixin` interface.\n",
    "\n",
    "    Attributes:\n",
    "        words_ (set): A set of unique words extracted from the input data.\n",
    "        replacement_words_ (dict): A dictionary mapping words to their replacement values.\n",
    "\n",
    "    Methods:\n",
    "        fit(X, y=None): Fit the transformer to the input data.\n",
    "        transform(X): Transform the input data into understandable features.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.words_ = None\n",
    "        self.replacement_words_ = None\n",
    "        with open(cfg['type_weather']) as file:\n",
    "            self.replacement_words_ = json.load(file)\n",
    "            \n",
    "    def fit(self, X: NDArray, y: NDArray = None) -> None:\n",
    "        \"\"\"\n",
    "        Fit the transformer to the input data.\n",
    "\n",
    "        This method extracts unique words from the input data, replaces them with their corresponding\n",
    "        replacement values, and stores the unique words in the `words_` attribute.\n",
    "\n",
    "        Args:\n",
    "            X (ndarray): The input data.\n",
    "            y (ndarray, optional): The target data. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "\n",
    "        \"\"\"\n",
    "        self.words_ = set()\n",
    "        Processed_Weather_Condition = X.dropna().apply(\n",
    "            lambda x: ' '.join(\n",
    "                set(\n",
    "                    sorted(\n",
    "                            [\n",
    "                            self.replacement_words_[word] for word in x.split(\" \") if word in self.replacement_words_.keys()\n",
    "                            ]\n",
    "                        )\n",
    "                    )\n",
    "                ) \n",
    "            )\n",
    "\n",
    "        for index in Processed_Weather_Condition.index:\n",
    "            if 'Mix' in Processed_Weather_Condition[index]:\n",
    "                Processed_Weather_Condition[index] = 'Mix'\n",
    "\n",
    "        X = Processed_Weather_Condition.replace({'': np.nan})\n",
    "        X.fillna(X.mode()[0], inplace=True)\n",
    "\n",
    "        for line in X:\n",
    "            for word in line.split(\" \"):\n",
    "                if not word in self.words_:\n",
    "                    self.words_.add(word)\n",
    "                    \n",
    "        return self\n",
    "                    \n",
    "    def transform(self, X: pd.Series) -> pd.Series:      \n",
    "        \"\"\"\n",
    "        Transform the input data into understable features.\n",
    "\n",
    "        This method takes the input data and encodes it into understable features based on the unique words\n",
    "        extracted during the fitting process.\n",
    "\n",
    "        Args:\n",
    "            X (pd.Series): The input data.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing the understable features.\n",
    "\n",
    "        \"\"\"\n",
    "        X.fillna(X.mode()[0], inplace=True)\n",
    "        new_columns = np.zeros((len(self.words_), len(X)), dtype=float)\n",
    "\n",
    "        for i, line in enumerate(X):\n",
    "            line_words = set(line.split(\" \"))\n",
    "            for k, word in enumerate(self.words_):\n",
    "                if word in line_words:\n",
    "                    new_columns[k][i] = 1.0\n",
    "\n",
    "        return_columns = dict()\n",
    "        for idx, word in enumerate(self.words_):\n",
    "            new_column = pd.Series(new_columns[idx])\n",
    "            new_column.index = X.index\n",
    "            return_columns[word] = new_column\n",
    "            \n",
    "        return pd.DataFrame(return_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>...</th>\n",
       "      <th>Roundabout</th>\n",
       "      <th>Station</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 05:46:00</td>\n",
       "      <td>2016-02-08 11:00:00</td>\n",
       "      <td>39.865147</td>\n",
       "      <td>-84.058723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-2</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:07:59</td>\n",
       "      <td>2016-02-08 06:37:59</td>\n",
       "      <td>39.928059</td>\n",
       "      <td>-82.831184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-3</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:49:27</td>\n",
       "      <td>2016-02-08 07:19:27</td>\n",
       "      <td>39.063148</td>\n",
       "      <td>-84.032608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-4</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 07:23:34</td>\n",
       "      <td>2016-02-08 07:53:34</td>\n",
       "      <td>39.747753</td>\n",
       "      <td>-84.205582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-5</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 07:39:07</td>\n",
       "      <td>2016-02-08 08:09:07</td>\n",
       "      <td>39.627781</td>\n",
       "      <td>-84.188354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>A-1009761</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-06-10 04:09:01</td>\n",
       "      <td>2021-06-10 05:45:47</td>\n",
       "      <td>28.436939</td>\n",
       "      <td>-81.348747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>A-1009762</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-06-10 04:09:54</td>\n",
       "      <td>2021-06-10 05:45:44</td>\n",
       "      <td>28.426664</td>\n",
       "      <td>-81.307961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>A-1009763</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-06-10 05:17:52</td>\n",
       "      <td>2021-06-10 06:42:43</td>\n",
       "      <td>27.765680</td>\n",
       "      <td>-82.641678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>A-1009764</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-06-10 05:24:46</td>\n",
       "      <td>2021-06-10 06:42:42</td>\n",
       "      <td>27.901506</td>\n",
       "      <td>-82.637878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>A-1009765</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-06-10 05:26:15</td>\n",
       "      <td>2021-06-10 09:30:38</td>\n",
       "      <td>28.302280</td>\n",
       "      <td>-82.704132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID   Source  Severity           Start_Time  \\\n",
       "0             A-1  Source2         3  2016-02-08 05:46:00   \n",
       "1             A-2  Source2         2  2016-02-08 06:07:59   \n",
       "2             A-3  Source2         2  2016-02-08 06:49:27   \n",
       "3             A-4  Source2         3  2016-02-08 07:23:34   \n",
       "4             A-5  Source2         2  2016-02-08 07:39:07   \n",
       "...           ...      ...       ...                  ...   \n",
       "999995  A-1009761  Source2         2  2021-06-10 04:09:01   \n",
       "999996  A-1009762  Source2         2  2021-06-10 04:09:54   \n",
       "999997  A-1009763  Source2         2  2021-06-10 05:17:52   \n",
       "999998  A-1009764  Source2         2  2021-06-10 05:24:46   \n",
       "999999  A-1009765  Source2         2  2021-06-10 05:26:15   \n",
       "\n",
       "                   End_Time  Start_Lat  Start_Lng  End_Lat  End_Lng  \\\n",
       "0       2016-02-08 11:00:00  39.865147 -84.058723      NaN      NaN   \n",
       "1       2016-02-08 06:37:59  39.928059 -82.831184      NaN      NaN   \n",
       "2       2016-02-08 07:19:27  39.063148 -84.032608      NaN      NaN   \n",
       "3       2016-02-08 07:53:34  39.747753 -84.205582      NaN      NaN   \n",
       "4       2016-02-08 08:09:07  39.627781 -84.188354      NaN      NaN   \n",
       "...                     ...        ...        ...      ...      ...   \n",
       "999995  2021-06-10 05:45:47  28.436939 -81.348747      NaN      NaN   \n",
       "999996  2021-06-10 05:45:44  28.426664 -81.307961      NaN      NaN   \n",
       "999997  2021-06-10 06:42:43  27.765680 -82.641678      NaN      NaN   \n",
       "999998  2021-06-10 06:42:42  27.901506 -82.637878      NaN      NaN   \n",
       "999999  2021-06-10 09:30:38  28.302280 -82.704132      NaN      NaN   \n",
       "\n",
       "        Distance(mi)  ... Roundabout Station   Stop Traffic_Calming  \\\n",
       "0               0.01  ...      False   False  False           False   \n",
       "1               0.01  ...      False   False  False           False   \n",
       "2               0.01  ...      False   False  False           False   \n",
       "3               0.01  ...      False   False  False           False   \n",
       "4               0.01  ...      False   False  False           False   \n",
       "...              ...  ...        ...     ...    ...             ...   \n",
       "999995          0.00  ...      False   False  False           False   \n",
       "999996          0.00  ...      False   False  False           False   \n",
       "999997          0.00  ...      False   False  False           False   \n",
       "999998          0.00  ...      False   False  False           False   \n",
       "999999          0.00  ...      False   False  False           False   \n",
       "\n",
       "       Traffic_Signal Turning_Loop Sunrise_Sunset Civil_Twilight  \\\n",
       "0               False        False          Night          Night   \n",
       "1               False        False          Night          Night   \n",
       "2                True        False          Night          Night   \n",
       "3               False        False          Night            Day   \n",
       "4                True        False            Day            Day   \n",
       "...               ...          ...            ...            ...   \n",
       "999995           True        False          Night          Night   \n",
       "999996          False        False          Night          Night   \n",
       "999997           True        False          Night          Night   \n",
       "999998          False        False          Night          Night   \n",
       "999999           True        False          Night          Night   \n",
       "\n",
       "       Nautical_Twilight Astronomical_Twilight  \n",
       "0                  Night                 Night  \n",
       "1                  Night                   Day  \n",
       "2                    Day                   Day  \n",
       "3                    Day                   Day  \n",
       "4                    Day                   Day  \n",
       "...                  ...                   ...  \n",
       "999995             Night                 Night  \n",
       "999996             Night                 Night  \n",
       "999997             Night                   Day  \n",
       "999998             Night                   Day  \n",
       "999999             Night                   Day  \n",
       "\n",
       "[1000000 rows x 46 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(cfg[\"dataset\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_colums = df.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "df = data_condersion(df)\n",
    "df = drop_excess_parametres(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the target column and feature columns\n",
    "\n",
    "target_column = 'Severity'\n",
    "feature_columns = list(df.columns)\n",
    "feature_columns.remove(target_column)\n",
    "\n",
    "X = df[feature_columns]\n",
    "Y = df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the City column\n",
    "count_encoder_city = ce.CountEncoder(normalize=True)\n",
    "x_train['City_Encoded'] = count_encoder_city.fit_transform(x_train['City'])\n",
    "x_test['City_Encoded'] = count_encoder_city.transform(x_test['City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the County column\n",
    "count_encoder_county = ce.CountEncoder(normalize=True)\n",
    "x_train['County_Encoded'] = count_encoder_county.fit_transform(x_train['County'])\n",
    "x_test['County_Encoded'] = count_encoder_county.transform(x_test['County'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the State column\n",
    "label_encoder_state = LabelEncoder()\n",
    "encoded = pd.Series(label_encoder_state.fit_transform(x_train['State']))\n",
    "encoded.index = x_train.index\n",
    "x_train['State_Encoded'] = encoded\n",
    "encoded = pd.Series(label_encoder_state.transform(x_test['State']))\n",
    "encoded.index = x_test.index\n",
    "x_test['State_Encoded'] = encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the Timezone and Wind_Direction columns\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, min_frequency=5*10**(-4), handle_unknown=\"ignore\")\n",
    "\n",
    "encoded_categorical_columns_train = pd.DataFrame(onehot_encoder.fit_transform(x_train[['Timezone', 'Wind_Direction']]))\n",
    "encoded_categorical_columns_test = pd.DataFrame(onehot_encoder.transform(x_test[['Timezone', 'Wind_Direction']]))\n",
    "\n",
    "encoded_categorical_columns_train.columns = onehot_encoder.get_feature_names_out()\n",
    "encoded_categorical_columns_train.index = x_train.index\n",
    "\n",
    "encoded_categorical_columns_test.columns = onehot_encoder.get_feature_names_out()\n",
    "encoded_categorical_columns_test.index = x_test.index\n",
    "\n",
    "for column_name in onehot_encoder.get_feature_names_out():\n",
    "    x_train[column_name] = encoded_categorical_columns_train[column_name]\n",
    "    x_test[column_name] = encoded_categorical_columns_test[column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the Weather_Condition column\n",
    "weather_transformer = WeatherEncoder()\n",
    "\n",
    "encoded_train = weather_transformer.fit_transform(x_train['Weather_Condition'])\n",
    "encoded_test = weather_transformer.transform(x_test['Weather_Condition'])\n",
    "\n",
    "for word in weather_transformer.words_:\n",
    "    x_train[word] = encoded_train[word]\n",
    "    x_test[word] = encoded_test[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original columns\n",
    "x_train.drop(columns=['Timezone',\n",
    "                      'Wind_Direction',\n",
    "                      'Weather_Condition',\n",
    "                      'State',\n",
    "                      'County',\n",
    "                      'City'\n",
    "                      ], inplace=True)\n",
    "x_test.drop(columns=['Timezone',\n",
    "                      'Wind_Direction',\n",
    "                      'Weather_Condition',\n",
    "                      'State',\n",
    "                      'County',\n",
    "                      'City'\n",
    "                      ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns\n",
    "feature_columns = list(x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "standard_scaler = StandardScaler()\n",
    "x_train.loc[:, feature_columns] = standard_scaler.fit_transform(x_train)\n",
    "x_test.loc[:, feature_columns] = standard_scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Pressure(in)</th>\n",
       "      <th>Visibility(mi)</th>\n",
       "      <th>Wind_Speed(mph)</th>\n",
       "      <th>Precipitation(in)</th>\n",
       "      <th>Amenity</th>\n",
       "      <th>Bump</th>\n",
       "      <th>Crossing</th>\n",
       "      <th>...</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Dust</th>\n",
       "      <th>Whirls</th>\n",
       "      <th>Cloudy</th>\n",
       "      <th>Fog</th>\n",
       "      <th>Hail</th>\n",
       "      <th>Snow</th>\n",
       "      <th>Ice</th>\n",
       "      <th>Thunder</th>\n",
       "      <th>Mix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>724212</th>\n",
       "      <td>-0.125238</td>\n",
       "      <td>-1.072822</td>\n",
       "      <td>1.143062</td>\n",
       "      <td>0.479091</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>1.496071</td>\n",
       "      <td>-0.101755</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.506464</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>-0.125238</td>\n",
       "      <td>2.033292</td>\n",
       "      <td>-2.429342</td>\n",
       "      <td>0.173988</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>0.295964</td>\n",
       "      <td>-0.009684</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663806</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855204</th>\n",
       "      <td>-0.125238</td>\n",
       "      <td>0.192632</td>\n",
       "      <td>-2.337742</td>\n",
       "      <td>-1.109983</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>0.461496</td>\n",
       "      <td>0.032793</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663806</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801341</th>\n",
       "      <td>-0.125238</td>\n",
       "      <td>-0.440095</td>\n",
       "      <td>-1.925542</td>\n",
       "      <td>0.517228</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>0.047666</td>\n",
       "      <td>-0.101755</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663806</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628599</th>\n",
       "      <td>-0.125238</td>\n",
       "      <td>0.710317</td>\n",
       "      <td>0.227061</td>\n",
       "      <td>0.479091</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>0.461496</td>\n",
       "      <td>-0.101755</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.506464</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264895</th>\n",
       "      <td>-0.117590</td>\n",
       "      <td>-0.727698</td>\n",
       "      <td>0.776661</td>\n",
       "      <td>0.453665</td>\n",
       "      <td>-0.077112</td>\n",
       "      <td>-0.407547</td>\n",
       "      <td>-0.009684</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663806</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373331</th>\n",
       "      <td>0.884337</td>\n",
       "      <td>-0.842739</td>\n",
       "      <td>1.051461</td>\n",
       "      <td>0.301114</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>2.447880</td>\n",
       "      <td>-0.101755</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663806</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134069</th>\n",
       "      <td>-0.125238</td>\n",
       "      <td>0.997920</td>\n",
       "      <td>-0.368340</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>1.020166</td>\n",
       "      <td>-0.009684</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>2.583518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.506464</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685564</th>\n",
       "      <td>-0.125238</td>\n",
       "      <td>-1.935631</td>\n",
       "      <td>-0.688940</td>\n",
       "      <td>0.695205</td>\n",
       "      <td>-0.009456</td>\n",
       "      <td>0.461496</td>\n",
       "      <td>-0.101755</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.387069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663806</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123952</th>\n",
       "      <td>-0.117590</td>\n",
       "      <td>-0.014442</td>\n",
       "      <td>-0.459940</td>\n",
       "      <td>0.440953</td>\n",
       "      <td>0.369266</td>\n",
       "      <td>-0.023545</td>\n",
       "      <td>-0.009684</td>\n",
       "      <td>-0.119052</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>2.583518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253852</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.663806</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.10119</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>-0.026828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784164 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Distance(mi)  Temperature(F)  Humidity(%)  Pressure(in)  \\\n",
       "724212     -0.125238       -1.072822     1.143062      0.479091   \n",
       "3957       -0.125238        2.033292    -2.429342      0.173988   \n",
       "855204     -0.125238        0.192632    -2.337742     -1.109983   \n",
       "801341     -0.125238       -0.440095    -1.925542      0.517228   \n",
       "628599     -0.125238        0.710317     0.227061      0.479091   \n",
       "...              ...             ...          ...           ...   \n",
       "264895     -0.117590       -0.727698     0.776661      0.453665   \n",
       "373331      0.884337       -0.842739     1.051461      0.301114   \n",
       "134069     -0.125238        0.997920    -0.368340      0.491803   \n",
       "685564     -0.125238       -1.935631    -0.688940      0.695205   \n",
       "123952     -0.117590       -0.014442    -0.459940      0.440953   \n",
       "\n",
       "        Visibility(mi)  Wind_Speed(mph)  Precipitation(in)   Amenity  \\\n",
       "724212        0.369266         1.496071          -0.101755 -0.119052   \n",
       "3957          0.369266         0.295964          -0.009684 -0.119052   \n",
       "855204        0.369266         0.461496           0.032793 -0.119052   \n",
       "801341        0.369266         0.047666          -0.101755 -0.119052   \n",
       "628599        0.369266         0.461496          -0.101755 -0.119052   \n",
       "...                ...              ...                ...       ...   \n",
       "264895       -0.077112        -0.407547          -0.009684 -0.119052   \n",
       "373331        0.369266         2.447880          -0.101755 -0.119052   \n",
       "134069        0.369266         1.020166          -0.009684 -0.119052   \n",
       "685564       -0.009456         0.461496          -0.101755 -0.119052   \n",
       "123952        0.369266        -0.023545          -0.009684 -0.119052   \n",
       "\n",
       "            Bump  Crossing  ...      Rain      Dust  Whirls    Cloudy  \\\n",
       "724212 -0.017715 -0.387069  ... -0.253852 -0.006961     0.0  1.506464   \n",
       "3957   -0.017715 -0.387069  ... -0.253852 -0.006961     0.0 -0.663806   \n",
       "855204 -0.017715 -0.387069  ... -0.253852 -0.006961     0.0 -0.663806   \n",
       "801341 -0.017715 -0.387069  ... -0.253852 -0.006961     0.0 -0.663806   \n",
       "628599 -0.017715 -0.387069  ... -0.253852 -0.006961     0.0  1.506464   \n",
       "...          ...       ...  ...       ...       ...     ...       ...   \n",
       "264895 -0.017715 -0.387069  ... -0.253852 -0.006961     0.0 -0.663806   \n",
       "373331 -0.017715 -0.387069  ... -0.253852 -0.006961     0.0 -0.663806   \n",
       "134069 -0.017715  2.583518  ... -0.253852 -0.006961     0.0  1.506464   \n",
       "685564 -0.017715 -0.387069  ... -0.253852 -0.006961     0.0 -0.663806   \n",
       "123952 -0.017715  2.583518  ... -0.253852 -0.006961     0.0 -0.663806   \n",
       "\n",
       "             Fog      Hail     Snow       Ice   Thunder       Mix  \n",
       "724212 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "3957   -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "855204 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "801341 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "628599 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "...          ...       ...      ...       ...       ...       ...  \n",
       "264895 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "373331 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "134069 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "685564 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "123952 -0.111346 -0.001956 -0.10119 -0.007659 -0.070571 -0.026828  \n",
       "\n",
       "[784164 rows x 80 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(y_train), len(x_test), len(y_test)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(algorithm=&#x27;brute&#x27;, metric=&#x27;euclidean&#x27;, n_neighbors=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(algorithm=&#x27;brute&#x27;, metric=&#x27;euclidean&#x27;, n_neighbors=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', metric='euclidean', n_neighbors=300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=300,\n",
    "                           metric=\"euclidean\",\n",
    "                           algorithm=\"brute\",\n",
    "                           weights=\"uniform\"\n",
    "                           )\n",
    "\n",
    "knn.fit(X=x_train, y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.6283921130196158\n",
      "test=0.6235897957109462\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = knn.predict(X=x_train)\n",
    "y_test_pred = knn.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "1. With the algorithm \"brute\" and uniform weights, and using different metrics, we obtained approximately the same results for $10^5$ samples, and for $10^6$ samples, the results were about the same.\n",
    "\n",
    "2. The Ball_Tree method gave approximately the same results.\n",
    "\n",
    "3. The KD-tree method did not improve the results.\n",
    "\n",
    "4. When the number of nearest neighbors was set to 300, the results became approximately equal. This suggests that the model may have been over fitted with a small number of training samples. The final results for both datasets were approximately 0.62.\n",
    "\n",
    "5. For $10^6$ samples, it took approximately 22 minutes to complete, which suggests that it may not be suitable for very large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=10, min_samples_leaf=200, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, min_samples_leaf=200, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, min_samples_leaf=200, random_state=0)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, min_samples_leaf=200, criterion='gini', random_state=0)\n",
    "tree.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.8389342025392648\n",
      "test=0.8376768125035069\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = tree.predict(X=x_train)\n",
    "y_test_pred = tree.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: \n",
    "1. The decision tree provides a reasonably accurate prediction, with an accuracy of approximately 0.8 on a dataset with $10^6$ elements. However, for Severity level 42, the prediction is not accurate at all.\n",
    "\n",
    "2. By experimenting with the number of splits and maximum depth, it is possible to improve the accuracy. However, even with these optimizations, Severity 4 is still not accurately predicted.\n",
    "\n",
    "3. Switching from the Gini impurity to the entropy criterion does not significantly change the results.\n",
    "\n",
    "4. As the dataset size increases, the model begins to accurately predict Severity 4, although the proportion of correct predictions remains approximately 0.9.\n",
    "\n",
    "5. With a maximum depth of 10 and a minimum number of samples per leaf of 500 and using the Gini criterion, the model accurately predicts all four Severity levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, min_samples_leaf=30, n_estimators=10,\n",
       "                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, min_samples_leaf=30, n_estimators=10,\n",
       "                       random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5, min_samples_leaf=30, n_estimators=10,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=10,\n",
    "                                       max_depth=5,\n",
    "                                       min_samples_leaf=30,\n",
    "                                       criterion=\"gini\",\n",
    "                                       random_state=0,\n",
    "                                       )\n",
    "random_forest.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.9651641426974286\n",
      "test=0.9687976420367923\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = random_forest.predict(X=x_train)\n",
    "y_test_pred = random_forest.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: <br>\n",
    "The decision tree performs better, which is likely due to the presence of a large number of instances with two and three features. The random forest takes into account specific features, while also attempting to utilize various indicators. However, there is an excessive amount of data with two and three attributes, and everything falls within these categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=8,\n",
       "                                                   min_samples_leaf=200,\n",
       "                                                   random_state=0),\n",
       "                  max_features=0.9, max_samples=0.8, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=8,\n",
       "                                                   min_samples_leaf=200,\n",
       "                                                   random_state=0),\n",
       "                  max_features=0.9, max_samples=0.8, random_state=0)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=8, min_samples_leaf=200, random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=8, min_samples_leaf=200, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=8,\n",
       "                                                   min_samples_leaf=200,\n",
       "                                                   random_state=0),\n",
       "                  max_features=0.9, max_samples=0.8, random_state=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging = BaggingClassifier(n_estimators=10,\n",
    "                            max_samples=0.8,\n",
    "                            max_features=0.9,\n",
    "                            random_state=0,\n",
    "                            estimator=DecisionTreeClassifier(max_depth=8,\n",
    "                                                             min_samples_leaf=200,\n",
    "                                                             criterion='gini',\n",
    "                                                             random_state=0\n",
    "                                                             )\n",
    "                            )\n",
    "bagging.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.9766871633296067\n",
      "test=0.9763187315784124\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = bagging.predict(X=x_train)\n",
    "y_test_pred = bagging.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "1) Using Bagging with a Decision Tree Classifier with n_estimators = 3, max_samples = 0.8 and max_features = 0.9 produces very good results. At $10^5$, the accuracy is approximately 0.97, and the model correctly predicts all Severity levels.\n",
    "\n",
    "2) However, when using a larger dataset, retraining the model does not significantly improve the results. Changing parameters also does not produce a significant impact on the situation.\n",
    "\n",
    "3) Using a Decision Tree Classifier for the estimator does not lead to full retraining of the dataset, but the accuracy decreases to 0.89. It is worth noting, however, that 1 and 4 were not predicted well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;sigmoid&#x27;, max_iter=8000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;sigmoid&#x27;, max_iter=8000, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='sigmoid', max_iter=8000, random_state=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel=\"sigmoid\",\n",
    "          max_iter=8000,\n",
    "          random_state=0\n",
    "          )\n",
    "svm.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.5725175322695396\n",
      "test=0.5743978046549446\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = svm.predict(X=x_train)\n",
    "y_test_pred = svm.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "1) A Support Vector Machine (SVM) with a linear kernel is not effective. The accuracy of the model is 0.54.\n",
    "\n",
    "2) An SVM with a polynomial kernel also does not yield good results. The accuracy remains at 0.44, even when the degree of the polynomial is varied.\n",
    "\n",
    "3) An SVM using a radial basis function (RBF) also proves to be ineffective, with an accuracy of 0.47.\n",
    "\n",
    "4) Finally, an SVM with the sigmoid kernel also fails to deliver accurate predictions, with an average accuracy of 0.57."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='multinomial')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "logistic_regression.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.7907031493025745\n",
      "test=0.7905310435720913\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = logistic_regression.predict(X=x_train)\n",
    "y_test_pred = logistic_regression.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinLogisticClassifier(BaseEstimator):\n",
    "    def __init__(self, classes: list | None = None) -> None:\n",
    "        super().__init__()\n",
    "        self.classes_ = classes\n",
    "        self._Regressors = [\n",
    "            LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\"), # x_1, x_2 | x_3, x_4\n",
    "            LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\"), # x_1 | x_2\n",
    "            LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\") # x_3 | x_4\n",
    "        ]\n",
    "        \n",
    "    def fit(self, X: NDArray, y: NDArray) -> None:\n",
    "        train_classes = set(y)\n",
    "        if self.classes_ == None:\n",
    "            self.classes_ = list(train_classes)\n",
    "        elif not self.classes_ == train_classes:\n",
    "            ValueError(\"Not all classes were passed during initialization\") \n",
    "        \n",
    "        first_cls, second_cls = self.classes_[:2], self.classes_[2:]\n",
    "        \n",
    "        y_train_bin = [\n",
    "            0 if cls in first_cls else 1\n",
    "            for cls in y \n",
    "            ]\n",
    "        \n",
    "        self._Regressors[0].fit(X=X, y=y_train_bin)\n",
    "        \n",
    "        mask = y.isin(first_cls)\n",
    "        \n",
    "        first_X = X.loc[mask]\n",
    "        second_X = X.loc[~mask]\n",
    "        \n",
    "        first_y_train_bin = pd.Series([\n",
    "            0 if cls == first_cls[0] else 1\n",
    "            for cls in y.loc[mask]\n",
    "        ])\n",
    "        second_y_train_bin = pd.Series([\n",
    "            0 if cls == second_cls[0] else 1\n",
    "            for cls in y.loc[~mask]\n",
    "        ])\n",
    "        \n",
    "        self._fit(X=first_X, y=first_y_train_bin, bin_cls=0)\n",
    "        self._fit(X=second_X, y=second_y_train_bin, bin_cls=1)\n",
    "        \n",
    "    def _fit(self, X: pd.DataFrame, y: pd.Series, bin_cls: int) -> None:\n",
    "        self._Regressors[1 + bin_cls].fit(X=X, y=y)\n",
    "        \n",
    "    def predict(self, X: NDArray) -> NDArray:\n",
    "        y_bin = self._Regressors[0].predict(X=X)\n",
    "        mask = y_bin == 0\n",
    "        \n",
    "        first_X = X.loc[mask]\n",
    "        second_X = X.loc[~mask]\n",
    "                \n",
    "        y_bins = [None, None]\n",
    "        y_bins[0] = self._predict(first_X, 0)\n",
    "        y_bins[1] = self._predict(second_X, 1)\n",
    "        \n",
    "        k = [-1, -1]\n",
    "        encoded_classes = list()\n",
    "        \n",
    "        for cls in y_bin:\n",
    "            k[cls] += 1\n",
    "            encoded_classes.append((cls, y_bins[cls][k[cls]]))\n",
    "            \n",
    "        return np.array([\n",
    "            self._decode(cls) for cls in encoded_classes\n",
    "        ])\n",
    "            \n",
    "    def _predict(self, X: pd.DataFrame, bin_cls: int) -> NDArray:\n",
    "        return self._Regressors[1 + bin_cls].predict(X=X)\n",
    "    \n",
    "    def _decode(self, code: tuple):\n",
    "        code_book = {\n",
    "            (0, 0): self.classes_[0],\n",
    "            (0, 1): self.classes_[1],\n",
    "            (1, 0): self.classes_[2],\n",
    "            (1, 1): self.classes_[3]\n",
    "        }\n",
    "        return code_book[code]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_logistic_regression = BinLogisticClassifier([1, 4, 2, 3])\n",
    "bin_logistic_regression.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 73)) while a minimum of 1 is required by LogisticRegression.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[206], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbin_logistic_regression\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m bin_logistic_regression\u001b[38;5;241m.\u001b[39mpredict(X\u001b[38;5;241m=\u001b[39mx_test)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score(y_true\u001b[38;5;241m=\u001b[39my_train,\u001b[38;5;250m \u001b[39my_pred\u001b[38;5;241m=\u001b[39my_train_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score(y_true\u001b[38;5;241m=\u001b[39my_test,\u001b[38;5;250m \u001b[39my_pred\u001b[38;5;241m=\u001b[39my_test_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[204], line 55\u001b[0m, in \u001b[0;36mBinLogisticClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     52\u001b[0m second_X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m     54\u001b[0m y_bins \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m---> 55\u001b[0m y_bins[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m y_bins[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(second_X, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     58\u001b[0m k \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[204], line 70\u001b[0m, in \u001b[0;36mBinLogisticClassifier._predict\u001b[1;34m(self, X, bin_cls)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: pd\u001b[38;5;241m.\u001b[39mDataFrame, bin_cls: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDArray:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Regressors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbin_cls\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\kolos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:967\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 967\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    968\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    969\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    970\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    971\u001b[0m         )\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    974\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 73)) while a minimum of 1 is required by LogisticRegression."
     ]
    }
   ],
   "source": [
    "y_train_pred = bin_logistic_regression.predict(X=x_train)\n",
    "y_test_pred = bin_logistic_regression.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionReductingClassifier(BaseEstimator):\n",
    "    def __init__(self, classes: list | None = None) -> None:\n",
    "        super().__init__()\n",
    "        self.classes_ = classes\n",
    "        self._Regressors = [\n",
    "            LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\"), # x_1, x_2, x_3 | x_4\n",
    "            LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\"), # x_1,  x_2 | x_3\n",
    "            LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\") # x_1 | x_2\n",
    "        ]\n",
    "        \n",
    "    def fit(self, X: NDArray, y: NDArray) -> None:\n",
    "        train_classes = set(y)\n",
    "        if self.classes_ == None:\n",
    "            self.classes_ = list(train_classes)\n",
    "        elif not self.classes_ == train_classes:\n",
    "            ValueError(\"Not all classes were passed during initialization\") \n",
    "            \n",
    "        for i in range(len(self._Regressors)):\n",
    "            classes = self.classes_[:len(self._Regressors) + 1 - i]\n",
    "            mask = y.isin(classes)\n",
    "            self._fit(X=X[mask], y=y[mask], n_regressor=i, classes=classes)\n",
    "        \n",
    "    def _fit(self, X: pd.DataFrame, y: pd.Series, n_regressor: int, classes: list) -> None:\n",
    "        first_cls, second_cls = classes[:-1], classes[-1]\n",
    "        \n",
    "        y_train_bin = [\n",
    "            0 if cls in first_cls else 1\n",
    "            for cls in y \n",
    "            ]\n",
    "        \n",
    "        self._Regressors[n_regressor].fit(X=X, y=y_train_bin)\n",
    "        \n",
    "    def predict(self, X: pd.DataFrame) -> NDArray:\n",
    "        \n",
    "        y_predict = np.zeros(len(X), dtype=int)\n",
    "        \n",
    "        for i in range(len(self._Regressors)):\n",
    "            y_bin = self._predict(X=X, n_regressor=i)\n",
    "            mask = y_bin == 0\n",
    "            X = X.loc[mask]\n",
    "            k = 0\n",
    "            for idx, y in enumerate(y_predict):\n",
    "                if y == 0:\n",
    "                    if y_bin[k] == 1:\n",
    "                        y_predict[idx] = self.classes_[-(i + 1)]\n",
    "                    k += 1\n",
    "                    \n",
    "            if len(X) == 0: \n",
    "                return y_predict\n",
    "            \n",
    "        return y_predict\n",
    "            \n",
    "            \n",
    "    def _predict(self, X: pd.DataFrame, n_regressor: int) -> NDArray:\n",
    "        return self._Regressors[n_regressor].predict(X=X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_reducting = LogisticRegressionReductingClassifier([1, 4, 3, 2])\n",
    "logistic_regression_reducting.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "train=0.6371709523325542\n",
      "test=0.6441711556052444\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = logistic_regression_reducting.predict(X=x_train)\n",
    "y_test_pred = logistic_regression_reducting.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "1) Based on a large dataset, logistic regression produces a fairly accurate result, approximately 0.8.\n",
    "\n",
    "2) If you use a sufficiently large dataset, the main issue is that during the first iteration of the regression, there is a tendency for the model to overfit, which can lead to problems and rarely produces accurate predictions for 1 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bassian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bassian = GaussianNB()\n",
    "bassian.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.04845512755361317\n",
      "test=0.552393535928448\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = bassian.predict(X=x_train)\n",
    "y_test_pred = bassian.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "Due to the fact that the data is unbalanced, the results are not accurate. Additionally, it should be noted that the assumption of uncorrelated data may not be valid. There is a slight error in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis(solver=&#x27;lsqr&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis(solver=&#x27;lsqr&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis(solver='lsqr')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminant_analyse = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "discriminant_analyse.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=0.6319239760138226\n",
      "test=0.6391401565199716\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = discriminant_analyse.predict(X=x_train)\n",
    "y_test_pred = discriminant_analyse.predict(X=x_test)\n",
    "\n",
    "print(\n",
    "    f\"train={accuracy_score(y_true=y_train, y_pred=y_train_pred)}\"\n",
    "    \"\\n\"\n",
    "    f\"test={accuracy_score(y_true=y_test, y_pred=y_test_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты: <br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: 73, 2: 43259, 3: 35354, 4: 26}, {1: 0, 2: 43321, 3: 35391, 4: 0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_predicted_Severity = dict.fromkeys([1, 2, 3, 4], 0)\n",
    "count_real_Severity = dict.fromkeys([1, 2, 3, 4], 0)\n",
    "\n",
    "for p, r in zip(y_train_pred, y_train):\n",
    "    count_real_Severity[r] += 1\n",
    "    count_predicted_Severity[p] += 1\n",
    "    \n",
    "count_real_Severity, count_predicted_Severity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
